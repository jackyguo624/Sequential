# pytorch_lightning==2.5.1
seed_everything: true
model:
  class_path: models.asr.dummy.models.dnn.Dnn
  init_args:
    input_dim: 80
    hidden_dim: 100
    output_dim: 80

data:
  class_path: sequential.data.lhotse_datamodule.LhotseManifestDataModule
  init_args:
    train_manifest_dir: export/aispeech/asr/collectionzh+en+fangyan-2w-asr/dev
    train_dataset:
      class_path: sequential.data.dataset.K2SpeechRecognitionDatasetWraper
      init_args:
        input_strategy:
          class_path: lhotse.dataset.input_strategies.OnTheFlyFeatures
          init_args:
            extractor:
              class_path: lhotse.features.kaldi.extractors.Fbank
              init_args:
                config:
                  num_mel_bins: 80
    train_sampler:
      class_path: lhotse.dataset.sampling.SimpleCutSampler
      init_args:
        max_duration: 50
        shuffle: True
    audio_backend:
      class_path: sequential.data.audio_backend.KaldiAudioBackend
      init_args:
        force_sampling_rate: 16000


trainer:
  default_root_dir: fireredasr_npu
  max_epochs: 1
  logger: true
  accelerator:
    class_path: lightning_npu.accelerators.npu.NPUAccelerator
  devices: 1
  strategy:
    class_path: lightning_npu.strategies.npu.SingleNPUStrategy
  use_distributed_sampler: false

